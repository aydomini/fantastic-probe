#!/bin/bash
export LC_ALL=C.UTF-8

#==============================================================================
# Fantastic-Probe Upload Library
# Provides automatic JSON upload to network storage functionality
# Author: Fantastic-Probe Team
#==============================================================================

set -euo pipefail

#==============================================================================
# Configuration
#==============================================================================

# Upload database path
UPLOAD_CACHE_DB="${UPLOAD_CACHE_DB:-/var/lib/fantastic-probe/upload_cache.db}"

# Upload lock file (ensure serial uploads)
UPLOAD_LOCK_FILE="${UPLOAD_LOCK_FILE:-/tmp/fantastic-probe-upload.lock}"

# Upload interval (seconds between uploads, default 15s)
UPLOAD_INTERVAL="${UPLOAD_INTERVAL:-15}"

# Log file path (inherit from main config if available)
LOG_FILE="${LOG_FILE:-/var/log/fantastic_probe.log}"
ERROR_LOG_FILE="${ERROR_LOG_FILE:-/var/log/fantastic_probe_errors.log}"

# Ensure upload cache directory exists
CACHE_DIR=$(dirname "$UPLOAD_CACHE_DB")
mkdir -p "$CACHE_DIR"

#==============================================================================
# Logging functions (compatible with existing log system)
#==============================================================================

upload_log() {
    local timestamp
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [UPLOAD] $1" >> "$LOG_FILE"
}

upload_log_info() {
    upload_log "â„¹ï¸  INFO: $1"
}

upload_log_warn() {
    upload_log "âš ï¸  WARN: $1"
}

upload_log_error() {
    upload_log "âŒ ERROR: $1"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [UPLOAD] $1" >> "$ERROR_LOG_FILE"
}

upload_log_success() {
    upload_log "âœ… SUCCESS: $1"
}

upload_log_debug() {
    if [ "${DEBUG:-false}" = "true" ]; then
        upload_log "ğŸ” DEBUG: $1"
    fi
}

#==============================================================================
# æ§åˆ¶å°è¾“å‡ºå‡½æ•° (ç”¨äºå®æ—¶åé¦ˆ)
#==============================================================================

upload_console() {
    # è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ŒåŒæ—¶å†™å…¥æ—¥å¿—
    echo "$1"
}

upload_console_info() {
    local msg="â„¹ï¸  INFO: $1"
    upload_console "$msg"
    upload_log "$msg"
}

upload_console_warn() {
    local msg="âš ï¸  WARN: $1"
    upload_console "$msg"
    upload_log "$msg"
}

upload_console_error() {
    local msg="âŒ ERROR: $1"
    upload_console "$msg"
    upload_log "$msg"
    echo "[$( date '+%Y-%m-%d %H:%M:%S')] [UPLOAD] $1" >> "$ERROR_LOG_FILE"
}

upload_console_success() {
    local msg="âœ… SUCCESS: $1"
    upload_console "$msg"
    upload_log "$msg"
}

#==============================================================================
# Database initialization
#==============================================================================

init_upload_cache_db() {
    # Initialize SQLite database for upload tracking
    sqlite3 "$UPLOAD_CACHE_DB" <<'SQL'
CREATE TABLE IF NOT EXISTS upload_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    json_file TEXT NOT NULL UNIQUE,
    target_path TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'pending',
    upload_count INTEGER DEFAULT 0,
    last_upload_time INTEGER,
    last_error_message TEXT,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_status ON upload_cache(status);
CREATE INDEX IF NOT EXISTS idx_json_file ON upload_cache(json_file);
CREATE INDEX IF NOT EXISTS idx_last_upload_time ON upload_cache(last_upload_time);
SQL

    upload_log_debug "ä¸Šä¼ ç¼“å­˜æ•°æ®åº“å·²åˆå§‹åŒ–: $UPLOAD_CACHE_DB"
}

#==============================================================================
# Path mapping function
#==============================================================================

# Legacy function for backward compatibility
calculate_target_path() {
    local json_file="$1"
    calculate_target_path_universal "$json_file" "json"
}

# Universal path mapping function
# Supports: multiple file types, TV shows structure, arbitrary nesting
calculate_target_path_universal() {
    local source_file="$1"
    local file_type="${2:-auto}"  # auto, json, nfo, srt, ass, ssa, png, jpg

    # Validate source file exists
    if [ ! -f "$source_file" ]; then
        upload_log_error "æºæ–‡ä»¶ä¸å­˜åœ¨: $source_file"
        return 1
    fi

    local source_dir=$(dirname "$source_file")
    local source_name=$(basename "$source_file")
    local source_ext="${source_name##*.}"

    # Auto-detect file type if needed
    if [ "$file_type" = "auto" ]; then
        case "$source_ext" in
            json) file_type="json" ;;
            nfo)  file_type="nfo" ;;
            srt)  file_type="srt" ;;
            ass)  file_type="ass" ;;
            ssa)  file_type="ssa" ;;
            png)  file_type="png" ;;
            jpg|jpeg) file_type="jpg" ;;
            *)
                upload_log_error "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: $source_ext"
                return 1
                ;;
        esac
    fi

    upload_log_debug "å¤„ç†æ–‡ä»¶: $source_name (ç±»å‹: $file_type)"

    # Step 1: Find corresponding STRM file (same directory first, then subdirectories)
    local base_name strm_file

    case "$file_type" in
        json)
            # movie.iso-mediainfo.json -> movie.iso.strm
            base_name="${source_name%.iso-mediainfo.json}.iso"
            strm_file="${source_dir}/${base_name}.strm"
            ;;
        nfo|png|jpg)
            # movie.iso.nfo -> movie.iso.strm
            # poster.png -> movie.iso.strm (éœ€è¦æŸ¥æ‰¾åŒç›®å½•çš„ .iso.strm)
            # tvshow.nfo -> æŸ¥æ‰¾å­ç›®å½•çš„ .iso.strm (Show-level)
            base_name="${source_name%.*}"
            # å¦‚æœæ˜¯ .iso.nfo è¿™ç§æ ¼å¼
            if [[ "$base_name" == *.iso ]]; then
                strm_file="${source_dir}/${base_name}.strm"
            else
                # å›¾ç‰‡æˆ–é€šç”¨ NFO æ–‡ä»¶ï¼šå…ˆæŸ¥æ‰¾åŒç›®å½•
                strm_file=$(find "$source_dir" -maxdepth 1 -name "*.iso.strm" 2>/dev/null | head -n 1)
            fi
            ;;
        srt|ass|ssa)
            # movie.iso.en.srt -> movie.iso.strm
            # movie.iso.zh.ass -> movie.iso.strm
            base_name="$source_name"
            # ç§»é™¤å­—å¹•æ–‡ä»¶çš„è¯­è¨€æ ‡è®°å’Œæ‰©å±•å
            base_name=$(echo "$base_name" | sed -E 's/\.(srt|ass|ssa)$//')
            # ç§»é™¤è¯­è¨€ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰: .en, .zh, .ja, .ko, .fr, .de, .es
            base_name=$(echo "$base_name" | sed -E 's/\.(en|zh|ja|ko|fr|de|es|zh-CN|zh-TW|pt-BR)$//')
            strm_file="${source_dir}/${base_name}.strm"
            ;;
    esac

    # If STRM not found in same directory, search subdirectories (Show-level files)
    if [ ! -f "$strm_file" ] || [ -z "$strm_file" ]; then
        upload_log_debug "åŒç›®å½•æ—  STRMï¼ŒæŸ¥æ‰¾å­ç›®å½•..."
        strm_file=$(find "$source_dir" -maxdepth 2 -name "*.iso.strm" 2>/dev/null | head -n 1)
    fi

    # Validate STRM file exists
    if [ ! -f "$strm_file" ]; then
        upload_log_error "æ‰¾ä¸åˆ°å¯¹åº”çš„ STRM æ–‡ä»¶"
        upload_log_debug "  æºæ–‡ä»¶: $source_file"
        upload_log_debug "  æºç›®å½•: $source_dir"
        return 1
    fi

    local strm_dir=$(dirname "$strm_file")
    upload_log_debug "ä½¿ç”¨ STRM: $strm_file"

    # Step 2: Read STRM content (network storage ISO path)
    local iso_path
    iso_path=$(head -n 1 "$strm_file" | tr -d '\r\n')

    if [ -z "$iso_path" ]; then
        upload_log_error "STRM æ–‡ä»¶å†…å®¹ä¸ºç©º: $strm_file"
        return 1
    fi

    upload_log_debug "STRM å†…å®¹: $iso_path"

    # Step 3: Calculate target path
    local target_path

    if [ "$source_dir" = "$strm_dir" ]; then
        # Episode-level file: same directory as STRM
        # source_dir: /STRM/tv/Show/Season 01
        # strm_dir:   /STRM/tv/Show/Season 01
        # iso_path:   /storage/tv/Show/Season 01/episode.iso
        # target:     /storage/tv/Show/Season 01/episode.iso.nfo
        local storage_dir="${iso_path%/*}"
        target_path="${storage_dir}/${source_name}"
        upload_log_debug "Episode-level æ–‡ä»¶: $source_name"
    else
        # Show-level file: parent directory of STRM
        # source_dir: /STRM/tv/Show
        # strm_dir:   /STRM/tv/Show/Season 01
        # iso_path:   /storage/tv/Show/Season 01/episode.iso
        # target:     /storage/tv/Show/tvshow.nfo
        local show_storage_dir
        show_storage_dir=$(dirname "$(dirname "$iso_path")")
        target_path="${show_storage_dir}/${source_name}"
        upload_log_debug "Show-level æ–‡ä»¶: $source_name"
    fi

    upload_log_debug "è·¯å¾„æ˜ å°„: $(basename "$source_file") -> $target_path"
    echo "$target_path"
    return 0
}

#==============================================================================
# Database record functions
#==============================================================================

record_upload_pending() {
    local json_file="$1"
    local target_path="$2"
    local now
    now=$(date +%s)

    sqlite3 "$UPLOAD_CACHE_DB" <<SQL
INSERT OR REPLACE INTO upload_cache (json_file, target_path, status, created_at, updated_at)
VALUES ('$json_file', '$target_path', 'pending', $now, $now);
SQL

    upload_log_debug "è®°å½•å¾…ä¸Šä¼ : $json_file"
}

record_upload_success() {
    local json_file="$1"
    local now
    now=$(date +%s)

    sqlite3 "$UPLOAD_CACHE_DB" <<SQL
UPDATE upload_cache
SET status = 'success',
    upload_count = upload_count + 1,
    last_upload_time = $now,
    last_error_message = NULL,
    updated_at = $now
WHERE json_file = '$json_file';
SQL

    upload_log_success "ä¸Šä¼ æˆåŠŸ: $json_file"
}

record_upload_failure() {
    local json_file="$1"
    local error_message="$2"
    local now
    now=$(date +%s)

    # Escape single quotes in error message
    error_message="${error_message//\'/\'\'}"

    sqlite3 "$UPLOAD_CACHE_DB" <<SQL
UPDATE upload_cache
SET status = 'failed',
    upload_count = upload_count + 1,
    last_upload_time = $now,
    last_error_message = '$error_message',
    updated_at = $now
WHERE json_file = '$json_file';
SQL

    upload_log_error "ä¸Šä¼ å¤±è´¥: $json_file - $error_message"
}

#==============================================================================
# Core upload function (with flock for serial execution)
#==============================================================================

upload_json_single() {
    local json_file="$1"
    local target_path="$2"  # Optional: pre-calculated target path

    # Validate JSON file exists
    if [ ! -f "$json_file" ]; then
        upload_log_error "æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ : $json_file"
        return 1
    fi

    # Calculate target path if not provided
    if [ -z "$target_path" ]; then
        if ! target_path=$(calculate_target_path "$json_file"); then
            record_upload_failure "$json_file" "è·¯å¾„æ˜ å°„å¤±è´¥"
            upload_console_error "è·¯å¾„æ˜ å°„å¤±è´¥: $(basename "$json_file")"
            return 1
        fi
    fi

    # Record pending status
    record_upload_pending "$json_file" "$target_path"

    # Acquire upload lock (ensure serial uploads)
    upload_log_info "ç­‰å¾…ä¸Šä¼ é”: $(basename "$json_file")"

    (
        # Use flock to ensure only one upload at a time
        flock -x 201

        upload_log_info "å¼€å§‹ä¸Šä¼ : $(basename "$json_file")"
        upload_log_debug "  æºæ–‡ä»¶: $json_file"
        upload_log_debug "  ç›®æ ‡è·¯å¾„: $target_path"

        # Ensure target directory exists
        local target_dir
        target_dir=$(dirname "$target_path")

        if [ ! -d "$target_dir" ]; then
            upload_log_info "  åˆ›å»ºç›®æ ‡ç›®å½•: $target_dir"
            if ! mkdir -p "$target_dir" 2>/dev/null; then
                record_upload_failure "$json_file" "æ— æ³•åˆ›å»ºç›®æ ‡ç›®å½•: $target_dir"
                upload_console_error "æ— æ³•åˆ›å»ºç›®æ ‡ç›®å½•: $target_dir"
                return 1
            fi
        fi

        # Perform upload (copy JSON to target path)
        local start_time
        start_time=$(date +%s)

        if cp "$json_file" "$target_path" 2>/dev/null; then
            local end_time
            end_time=$(date +%s)
            local duration=$((end_time - start_time))

            # Record success
            record_upload_success "$json_file"
            upload_console_success "$(basename "$json_file") (è€—æ—¶: ${duration}ç§’)"
            upload_log_success "ä¸Šä¼ å®Œæˆ: $(basename "$json_file") (è€—æ—¶: ${duration}ç§’)"

            return 0
        else
            # Record failure
            local error_msg="å¤åˆ¶æ–‡ä»¶å¤±è´¥"
            record_upload_failure "$json_file" "$error_msg"
            upload_console_error "$(basename "$json_file"): $error_msg"
            return 1
        fi

    ) 201>"$UPLOAD_LOCK_FILE"

    return $?
}

#==============================================================================
# Async upload wrapper (non-blocking)
#==============================================================================

upload_json_async() {
    local json_file="$1"

    # Launch upload in background
    upload_log_debug "å¼‚æ­¥ä¸Šä¼ ä»»åŠ¡å¯åŠ¨: $(basename "$json_file")"

    (
        upload_json_single "$json_file"
    ) &

    # Detach from parent process
    disown
}

#==============================================================================
# Bulk upload function (for existing JSON files)
#==============================================================================

upload_all_pending() {
    local strm_root="${1:-$STRM_ROOT}"
    local file_types="${UPLOAD_FILE_TYPES:-json}"

    upload_log_info "å¼€å§‹æ‰¹é‡ä¸Šä¼ æ‰«æ: $strm_root (ç±»å‹: $file_types)"
    upload_console_info "æ‰«æç›®å½•: $strm_root"
    upload_console_info "ä¸Šä¼ ç±»å‹: $file_types"

    # Parse file types and build find patterns
    IFS=',' read -ra types_array <<< "$file_types"
    local find_patterns=()
    local first=true

    for type in "${types_array[@]}"; do
        type=$(echo "$type" | tr -d ' ')  # Remove spaces
        case "$type" in
            json)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.iso-mediainfo.json")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.iso-mediainfo.json")
                fi
                ;;
            nfo)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.nfo")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.nfo")
                fi
                ;;
            srt)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.srt")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.srt")
                fi
                ;;
            ass)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.ass")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.ass")
                fi
                ;;
            ssa)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.ssa")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.ssa")
                fi
                ;;
            png)
                if [ "$first" = true ]; then
                    find_patterns+=("-name" "*.png")
                    first=false
                else
                    find_patterns+=("-o" "-name" "*.png")
                fi
                ;;
            jpg)
                if [ "$first" = true ]; then
                    find_patterns+=("(" "-name" "*.jpg" "-o" "-name" "*.jpeg" ")")
                    first=false
                else
                    find_patterns+=("-o" "(" "-name" "*.jpg" "-o" "-name" "*.jpeg" ")")
                fi
                ;;
        esac
    done

    if [ ${#find_patterns[@]} -eq 0 ]; then
        upload_console_error "æ²¡æœ‰é…ç½®æœ‰æ•ˆçš„ä¸Šä¼ æ–‡ä»¶ç±»å‹"
        return 1
    fi

    # Step 1: Find all directories containing .iso.strm files (grouped by directory)
    upload_console_info "æ‰«æ ISO ç›®å½•..."
    local -a strm_dirs=()
    while IFS= read -r strm_file; do
        local strm_dir=$(dirname "$strm_file")
        strm_dirs+=("$strm_dir")
    done < <(find "$strm_root" -type f -name "*.iso.strm" 2>/dev/null || true)

    # Remove duplicates and sort
    if [ ${#strm_dirs[@]} -eq 0 ]; then
        upload_console_warn "æœªæ‰¾åˆ°ä»»ä½• .iso.strm æ–‡ä»¶"
        return 0
    fi

    strm_dirs=($(printf '%s\n' "${strm_dirs[@]}" | sort -u))
    upload_console_info "æ‰¾åˆ° ${#strm_dirs[@]} ä¸ª ISO ç›®å½•"
    upload_console ""

    # Statistics
    local total_dirs=0
    local total_files=0
    local success_count=0
    local failure_count=0
    local skipped_count=0

    # Step 2: Process each directory
    for strm_dir in "${strm_dirs[@]}"; do
        total_dirs=$((total_dirs + 1))

        # Find all matching files in this directory (maxdepth 1)
        local -a dir_files=()
        while IFS= read -r file; do
            dir_files+=("$file")
        done < <(find "$strm_dir" -maxdepth 1 -type f \( "${find_patterns[@]}" \) 2>/dev/null || true)

        # Skip if no matching files
        if [ ${#dir_files[@]} -eq 0 ]; then
            continue
        fi

        # Display directory header
        local dir_name=$(basename "$strm_dir")
        upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        upload_console_info "[$total_dirs/${#strm_dirs[@]}] ç›®å½•: $dir_name"
        upload_console "  æ‰¾åˆ° ${#dir_files[@]} ä¸ªæ–‡ä»¶"
        upload_log_info "å¤„ç†ç›®å½• $total_dirs: $strm_dir (${#dir_files[@]} ä¸ªæ–‡ä»¶)"

        # Process files in this directory
        for file in "${dir_files[@]}"; do
            total_files=$((total_files + 1))

            # Check if file exists in database with success status
            local db_status
            db_status=$(sqlite3 "$UPLOAD_CACHE_DB" \
                "SELECT status FROM upload_cache WHERE json_file='$file';" 2>/dev/null || echo "")

            if [ "$db_status" = "success" ]; then
                upload_console "  [$(basename "$file")] â­ï¸  å·²ä¸Šä¼ "
                upload_log_debug "è·³è¿‡å·²ä¸Šä¼ : $(basename "$file")"
                skipped_count=$((skipped_count + 1))
                continue
            fi

            # Display file progress
            upload_console "  [$(basename "$file")]..."
            upload_log_info "  ä¸Šä¼ æ–‡ä»¶: $(basename "$file")"

            # Upload file (serial, blocking)
            if upload_file_single "$file"; then
                success_count=$((success_count + 1))
            else
                failure_count=$((failure_count + 1))
            fi
        done

        # Wait for batch interval (rate limiting between directories)
        # Only wait if this is not the last directory
        if [ $total_dirs -lt ${#strm_dirs[@]} ] && [ "$UPLOAD_INTERVAL" -gt 0 ]; then
            upload_console "  â±ï¸  ç­‰å¾… ${UPLOAD_INTERVAL} ç§’ï¼ˆæ‰¹æ¬¡é—´éš”ï¼‰..."
            upload_log_debug "ç­‰å¾… ${UPLOAD_INTERVAL} ç§’ï¼ˆæ‰¹æ¬¡é—´éš”ï¼‰"
            sleep "$UPLOAD_INTERVAL"
        fi

        upload_console ""
    done

    # Summary
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_console_info "æ‰¹é‡ä¸Šä¼ ç»Ÿè®¡"
    upload_console "  å¤„ç†ç›®å½•æ•°: $total_dirs"
    upload_console "  æ€»è®¡æ–‡ä»¶æ•°: $total_files"
    upload_console "  âœ… æˆåŠŸ: $success_count"
    upload_console "  âŒ å¤±è´¥: $failure_count"
    upload_console "  â­ï¸  è·³è¿‡(å·²ä¸Šä¼ ): $skipped_count"
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_log_info "æ‰¹é‡ä¸Šä¼ å®Œæˆ: å¤„ç† $total_dirs ä¸ªç›®å½•, æ€»è®¡ $total_files ä¸ªæ–‡ä»¶, æˆåŠŸ $success_count ä¸ª, å¤±è´¥ $failure_count ä¸ª, è·³è¿‡ $skipped_count ä¸ª"
}

# Upload single file (universal wrapper)
upload_file_single() {
    local file="$1"

    # Use universal path mapping for all files
    local target_path
    target_path=$(calculate_target_path_universal "$file" "auto")
    if [ $? -ne 0 ]; then
        upload_console_error "è·¯å¾„æ˜ å°„å¤±è´¥: $(basename "$file")"
        record_upload_failure "$file" "è·¯å¾„æ˜ å°„å¤±è´¥"
        return 1
    fi

    # Execute upload with calculated target path
    upload_json_single "$file" "$target_path"
}

#==============================================================================
# Retry failed uploads
#==============================================================================

retry_failed_uploads() {
    upload_log_info "å¼€å§‹é‡è¯•å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡"
    upload_console_info "æŸ¥è¯¢å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡..."

    local success_count=0
    local failure_count=0

    # Query all failed uploads from database
    local failed_files
    failed_files=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "SELECT json_file FROM upload_cache WHERE status='failed' ORDER BY updated_at;" 2>/dev/null || echo "")

    if [ -z "$failed_files" ]; then
        upload_console_info "æ²¡æœ‰å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡"
        upload_log_info "æ²¡æœ‰å¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡"
        return 0
    fi

    # Count total failed files
    local total_failed=0
    while IFS= read -r json_file; do
        if [ -n "$json_file" ]; then
            total_failed=$((total_failed + 1))
        fi
    done <<< "$failed_files"

    upload_console_info "æ‰¾åˆ° $total_failed ä¸ªå¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡ï¼Œå¼€å§‹é‡è¯•..."
    upload_console ""

    local current_index=0
    # Retry each failed file
    while IFS= read -r json_file; do
        if [ -z "$json_file" ]; then
            continue
        fi

        current_index=$((current_index + 1))
        upload_console "[$current_index/$total_failed] $(basename "$json_file")..."
        upload_log_info "é‡è¯•ä¸Šä¼ : $(basename "$json_file")"

        # Upload file (serial, blocking)
        if upload_json_single "$json_file"; then
            success_count=$((success_count + 1))
        else
            failure_count=$((failure_count + 1))
        fi

    done <<< "$failed_files"

    # Summary
    upload_console ""
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_console_info "é‡è¯•å®Œæˆ"
    upload_console "  âœ… é‡è¯•æˆåŠŸ: $success_count ä¸ª"
    upload_console "  âŒ ä»ç„¶å¤±è´¥: $failure_count ä¸ª"
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_log_info "é‡è¯•å®Œæˆ: æˆåŠŸ $success_count ä¸ª, ä»å¤±è´¥ $failure_count ä¸ª"
}

#==============================================================================
# Cleanup and maintenance
#==============================================================================

cleanup_upload_cache() {
    local days_to_keep="${1:-30}"

    upload_log_info "æ¸…ç† $days_to_keep å¤©å‰çš„ä¸Šä¼ è®°å½•"

    local cutoff_time
    cutoff_time=$(date -d "$days_to_keep days ago" +%s 2>/dev/null || date -v-${days_to_keep}d +%s)

    local deleted_count
    deleted_count=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "DELETE FROM upload_cache WHERE status='success' AND updated_at < $cutoff_time; SELECT changes();" 2>/dev/null || echo "0")

    upload_log_info "å·²æ¸…ç† $deleted_count æ¡æ—§è®°å½•"
}

get_upload_stats() {
    upload_log_info "ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯:"
    upload_console_info "æŸ¥è¯¢ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯..."

    local total_count
    total_count=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "SELECT COUNT(*) FROM upload_cache;" 2>/dev/null || echo "0")

    local success_count
    success_count=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "SELECT COUNT(*) FROM upload_cache WHERE status='success';" 2>/dev/null || echo "0")

    local failed_count
    failed_count=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "SELECT COUNT(*) FROM upload_cache WHERE status='failed';" 2>/dev/null || echo "0")

    local pending_count
    pending_count=$(sqlite3 "$UPLOAD_CACHE_DB" \
        "SELECT COUNT(*) FROM upload_cache WHERE status='pending';" 2>/dev/null || echo "0")

    upload_console ""
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_console_info "ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯"
    upload_console "  æ€»è®¡: $total_count ä¸ªæ–‡ä»¶"
    upload_console "  âœ… æˆåŠŸ: $success_count ä¸ª"
    upload_console "  âŒ å¤±è´¥: $failed_count ä¸ª"
    upload_console "  â³ å¾…ä¸Šä¼ : $pending_count ä¸ª"
    upload_console "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    upload_console ""

    upload_log_info "  æ€»è®¡: $total_count"
    upload_log_info "  æˆåŠŸ: $success_count"
    upload_log_info "  å¤±è´¥: $failed_count"
    upload_log_info "  å¾…ä¸Šä¼ : $pending_count"
}

#==============================================================================
# Initialization on library load
#==============================================================================

# Initialize database when library is sourced
init_upload_cache_db
